#!/usr/bin/env node
import { intro, outro, select, text, confirm, spinner } from '@clack/prompts';
import { green, lightCyan, red, yellow } from 'kolorist';
import fs from 'fs/promises';
import path from 'path';
import os from 'os';
import { fileExists } from './utils.js';
import { execa } from 'execa';

// Check if running in non-interactive mode
const isNonInteractive = process.env.AIFILES_NON_INTERACTIVE === 'true' ||
                        process.argv.includes('--non-interactive') ||
                        !process.stdout.isTTY;

export async function checkSystemDependencies(): Promise<Record<string, boolean>> {
  const deps = {
    pandoc: false,
    exiftool: false,
    pdftotext: false,
    in2csv: false,
  };

  try {
    await execa('pandoc', ['--version']);
    deps.pandoc = true;
  } catch {}

  try {
    await execa('exiftool', ['-ver']);
    deps.exiftool = true;
  } catch {}

  try {
    await execa('pdftotext', ['-v']);
    deps.pdftotext = true;
  } catch {}

  try {
    await execa('in2csv', ['--version']);
    deps.in2csv = true;
  } catch {}

  return deps;
}

export async function checkOllama(): Promise<boolean> {
  try {
    await execa('ollama', ['list']);
    return true;
  } catch {
    return false;
  }
}

// Export the main setup function for testing
export async function runSetupWizard(): Promise<void> {
  try {
    if (!isNonInteractive) intro(lightCyan(' ðŸ¤– AIFiles Setup Wizard '));
    console.log(lightCyan(' ðŸ¤– AIFiles Setup Wizard '));

    console.log('This wizard will help you set up AIFiles.\n');

    // Check system dependencies
    const s = spinner();
    s.start('Checking system dependencies...');
    const deps = await checkSystemDependencies();
    s.stop('System dependencies checked');

  const missingDeps = Object.entries(deps)
    .filter(([_, installed]) => !installed)
    .map(([name]) => name);

  if (missingDeps.length > 0) {
    console.log(yellow('\nâš ï¸  Missing system dependencies:'));
    missingDeps.forEach((dep) => console.log(`  - ${dep}`));
    console.log('\nInstall them with:');

    const platform = process.platform;
    if (platform === 'darwin') {
      console.log(green('  brew install pandoc exiftool poppler csvkit\n'));
    } else if (platform === 'linux') {
      console.log(green('  sudo apt install pandoc exiftool poppler-utils python3-csvkit\n'));
    } else if (platform === 'win32') {
      console.log(green('  choco install pandoc exiftool poppler csvkit\n'));
    }

    const continueAnyway = isNonInteractive ?
      (process.env.AIFILES_CONTINUE_WITHOUT_DEPS === 'true') :
      await confirm({
        message: 'Continue setup anyway?',
        initialValue: false,
      });

    if (!continueAnyway) {
      if (!isNonInteractive) outro(red('Setup cancelled. Install dependencies and try again.'));
      console.log(red('Setup cancelled. Install dependencies and try again.'));
      process.exit(1);
    }
  } else {
    console.log(green('\nâœ“ All system dependencies installed!\n'));
  }

  // Choose AI provider
  let provider: string;
  if (isNonInteractive) {
    provider = process.env.AIFILES_LLM_PROVIDER || 'ollama';
    console.log(green(`âœ“ AI provider: ${provider} (from environment)\n`));
  } else {
    provider = await select({
      message: 'Choose your AI provider:',
      options: [
        {
          value: 'ollama',
          label: 'Ollama (Local)',
          hint: 'Free, private, runs on your computer',
        },
        {
          value: 'openai',
          label: 'OpenAI/ChatGPT',
          hint: 'Best quality, requires API key',
        },
        {
          value: 'deepseek',
          label: 'DeepSeek',
          hint: 'High quality, affordable API',
        },
        {
          value: 'grok',
          label: 'Grok (X.AI)',
          hint: 'Requires Grok API key',
        },
        {
          value: 'lmstudio',
          label: 'LM Studio (Local)',
          hint: 'Free, private, runs on your computer',
        },
      ],
    }) as string;
  }

  let config = `# AIFiles Configuration
# Generated by setup wizard

# LLM Provider
LLM_PROVIDER=${provider}

`;

  let selectedModel = '';

  // Provider-specific configuration
  if (provider === 'openai') {
    const apiKey = isNonInteractive ?
      (process.env.AIFILES_OPENAI_API_KEY || '') :
      await text({
        message: 'Enter your OpenAI API key:',
        placeholder: 'sk-...',
        validate: (value) => {
          if (!value) return 'API key is required';
          if (!value.startsWith('sk-')) return 'Invalid API key format';
        },
      }) as string;

    if (!apiKey && isNonInteractive) {
      console.log(yellow('âš ï¸  OpenAI API key not provided in AIFILES_OPENAI_API_KEY\n'));
    }

    const model = isNonInteractive ?
      (process.env.AIFILES_LLM_MODEL || 'gpt-3.5-turbo') :
      await select({
        message: 'Choose model:',
        options: [
          { value: 'gpt-3.5-turbo', label: 'GPT-3.5 Turbo (Fast, cheap)' },
          { value: 'gpt-4', label: 'GPT-4 (Best quality)' },
          { value: 'gpt-4-turbo', label: 'GPT-4 Turbo (Balanced)' },
        ],
      }) as string;

    selectedModel = model;
    config += `OPENAI_API_KEY=${apiKey}
LLM_MODEL=${model}

`;
  } else if (provider === 'ollama') {
    const hasOllama = await checkOllama();

    if (!hasOllama) {
      console.log(yellow('\nâš ï¸  Ollama not found. Install it from: https://ollama.ai\n'));

      const installNow = isNonInteractive ?
        (process.env.AIFILES_CONTINUE_WITHOUT_OLLAMA !== 'false') :
        await confirm({
          message: 'Continue setup anyway?',
          initialValue: true,
        });

      if (!installNow) {
      if (!isNonInteractive) outro(red('Setup cancelled.'));
      console.log(red('Setup cancelled.'));
        process.exit(1);
      }
    } else {
      console.log(green('\nâœ“ Ollama is installed!\n'));
    }

    const model = isNonInteractive ?
      (process.env.AIFILES_LLM_MODEL || 'llama3.2') :
      await text({
        message: 'Enter model name:',
        placeholder: 'llama3.2',
        initialValue: 'llama3.2',
      }) as string;

    selectedModel = model;

    const baseUrl = isNonInteractive ?
      (process.env.AIFILES_LLM_BASE_URL || 'http://127.0.0.1:11434') :
      await text({
        message: 'Ollama base URL:',
        placeholder: 'http://127.0.0.1:11434',
        initialValue: 'http://127.0.0.1:11434',
      }) as string;

    config += `LLM_MODEL=${model}
LLM_BASE_URL=${baseUrl}

`;

    console.log(yellow('\nðŸ’¡ Tip: Install vision support with: ollama pull llava\n'));
  } else if (provider === 'grok') {
    const apiKey = isNonInteractive ?
      (process.env.AIFILES_GROK_API_KEY || '') :
      await text({
        message: 'Enter your Grok API key:',
        placeholder: 'xai-...',
        validate: (value) => {
          if (!value) return 'API key is required';
        },
      }) as string;

    if (!apiKey && isNonInteractive) {
      console.log(yellow('âš ï¸  Grok API key not provided in AIFILES_GROK_API_KEY\n'));
    }

    selectedModel = 'grok-beta';
    config += `GROK_API_KEY=${apiKey}
LLM_MODEL=grok-beta

`;
  } else if (provider === 'deepseek') {
    const apiKey = isNonInteractive ?
      (process.env.AIFILES_DEEPSEEK_API_KEY || '') :
      await text({
        message: 'Enter your DeepSeek API key:',
        placeholder: 'sk-...',
        validate: (value) => {
          if (!value) return 'API key is required';
          if (!value.startsWith('sk-')) return 'Invalid API key format';
        },
      }) as string;

    if (!apiKey && isNonInteractive) {
      console.log(yellow('âš ï¸  DeepSeek API key not provided in AIFILES_DEEPSEEK_API_KEY\n'));
    }

    const model = isNonInteractive ?
      (process.env.AIFILES_LLM_MODEL || 'deepseek-chat') :
      await select({
        message: 'Choose model:',
        options: [
          { value: 'deepseek-chat', label: 'DeepSeek Chat (Recommended)' },
          { value: 'deepseek-coder', label: 'DeepSeek Coder (Code-focused)' },
        ],
      }) as string;

    selectedModel = model;
    config += `DEEPSEEK_API_KEY=${apiKey}
LLM_MODEL=${model}

`;
  } else if (provider === 'lmstudio') {
    const baseUrl = isNonInteractive ?
      (process.env.AIFILES_LLM_BASE_URL || 'http://127.0.0.1:1234/v1') :
      await text({
        message: 'LM Studio base URL:',
        placeholder: 'http://127.0.0.1:1234/v1',
        initialValue: 'http://127.0.0.1:1234/v1',
      }) as string;

    const model = isNonInteractive ?
      (process.env.AIFILES_LLM_MODEL || 'local-model') :
      await text({
        message: 'Model name:',
        placeholder: 'local-model',
        initialValue: 'local-model',
      }) as string;

    selectedModel = model;
    config += `LLM_BASE_URL=${baseUrl}
LLM_MODEL=${model}

`;
  }

  // Add common configuration
  config += `# Field definitions file (what data to extract from files)
FIELDS_FILE=~/.aifiles/fields.json

# Options
PROMPT_FOR_CUSTOM_CONTEXT=true
PROMPT_FOR_REVISION_NUMBER=true
MAX_CONTENT_WORDS=50
MAX_MEDIA_DATA_SOURCES=50
MOVE_FILE_OPERATION=true

# Base directory
BASE_DIRECTORY=~

# Directory configurations
DOCUMENT_DIRECTORY=Documents
DOCUMENT_FILENAME_FORMAT={file_category_1}/{file_category_2}/{file_category_3}--{file_title}
DOCUMENT_FILE_NAME_CASE=snake

MUSIC_DIRECTORY=Music
MUSIC_FILENAME_FORMAT={music_artist}/{music_album}/{music_track_number}--{music_track_title}
MUSIC_FILE_NAME_CASE=kebab

PICTURES_DIRECTORY=Pictures
PICTURES_FILENAME_FORMAT={picture_date_taken}/{file_title}
PICTURES_FILE_NAME_CASE=lower_snake

VIDEOS_DIRECTORY=Videos
VIDEOS_FILENAME_FORMAT={file_category_1}/{file_category_2}/{file_title}
VIDEOS_FILE_NAME_CASE=upper_snake

ARCHIVES_DIRECTORY=Archives
ARCHIVES_FILENAME_FORMAT={file_category_1}/{file_category_2}/{file_title}--{file_date_created}
ARCHIVES_FILE_NAME_CASE=pascal

OTHERS_DIRECTORY=Others
OTHERS_FILENAME_FORMAT={file_category_1}/{file_category_2}/{file_title}
OTHERS_FILE_NAME_CASE=pascal
`;

  // Write configuration
  const configDir = path.join(os.homedir(), '.aifiles');
  const configPath = path.join(configDir, 'config');
  const configExists = await fileExists(configPath);

  if (configExists) {
    const overwrite = isNonInteractive ?
      (process.env.AIFILES_OVERWRITE_CONFIG === 'true') :
      await confirm({
        message: 'Configuration file already exists. Overwrite?',
        initialValue: false,
      });

    if (!overwrite) {
    if (!isNonInteractive) outro(yellow('Setup cancelled. Existing configuration preserved.'));
    console.log(yellow('Setup cancelled. Existing configuration preserved.'));
      process.exit(0);
    }

    // Backup existing config
    const backupPath = `${configPath}.backup`;
    await fs.copyFile(configPath, backupPath);
    console.log(yellow(`\nðŸ“¦ Existing config backed up to: ${backupPath}\n`));
  }

  // Ensure config directory exists
  await fs.mkdir(configDir, { recursive: true });

  await fs.writeFile(configPath, config, 'utf-8');

  // Copy .aifiles.json if it doesn't exist
  const promptPath = path.join(os.homedir(), '.aifiles.json');
  const promptExists = await fileExists(promptPath);

  if (!promptExists) {
    const sourcePath = path.join(process.cwd(), '.aifiles.json');
    const sourceExists = await fileExists(sourcePath);

    if (sourceExists) {
      await fs.copyFile(sourcePath, promptPath);
      console.log(green('âœ“ Copied .aifiles.json to home directory\n'));
    }
  }

  // Setup complete
  if (!isNonInteractive) outro(green('âœ“ Setup complete!'));
  console.log(green('âœ“ Setup complete!'));

  // Configuration summary
  const colorize = (text: string) => isNonInteractive ? text : green(text);
  const colorizeLight = (text: string) => isNonInteractive ? text : lightCyan(text);
  const colorizeYellow = (text: string) => isNonInteractive ? text : yellow(text);

  console.log('\n' + colorizeLight('ðŸ“‹ Configuration Summary:'));
  console.log(`  â€¢ Provider: ${colorize(provider)}`);
  console.log(`  â€¢ Model: ${colorize(selectedModel || 'default')}`);
  console.log(`  â€¢ Config file: ${colorize(configPath)}`);

  console.log('\n' + colorizeLight('ðŸš€ Next steps:'));
  console.log('  1. Test your setup:', colorize('aifiles path/to/your/file.pdf'));
  console.log('  2. Create templates:', colorize('aifiles-templates add'));
  console.log('  3. Manage templates:', colorize('aifiles-templates list'));
  console.log('  4. Get help:', colorize('aifiles --help'));

  console.log('\n' + colorizeYellow('ðŸ“š Documentation:'));
  console.log('  â€¢ Quick Start: https://github.com/jjuliano/aifiles/blob/main/QUICKSTART.md');
  console.log('  â€¢ Full Guide: https://github.com/jjuliano/aifiles/blob/main/README.md\n');

  // Offer to test configuration
  if (!isNonInteractive) {
    const testNow = await confirm({
      message: 'Would you like to test your configuration with a sample file?',
      initialValue: false,
    });

    if (testNow) {
      console.log('\n' + yellow('ðŸ’¡ Tip: Run "aifiles <path-to-file>" to test with your own files'));
    }
  } else {
    console.log('\nðŸ’¡ Tip: Run "aifiles <path-to-file>" to test with your own files');
  }
  } catch (error) {
    console.error('DEBUG: Error in runSetupWizard:', error);
    console.error('DEBUG: Error stack:', error.stack);
    throw error;
  }
}

// Run setup wizard if this file is executed directly
// Check if this is the setup wizard being run (either directly or via symlink)
const isSetupWizard = process.argv[1].includes('setup-wizard') ||
                      process.argv[1].endsWith('aifiles-setup') ||
                      import.meta.url.includes('setup-wizard');

if (isSetupWizard) {
  runSetupWizard().catch(console.error);
}
